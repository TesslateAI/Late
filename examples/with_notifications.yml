# Training with ntfy.sh Notifications
# Receive push notifications when checkpoints are saved or training completes

# Model and Dataset
base_model: "meta-llama/Llama-3.2-3B-Instruct"
dataset_name: "yahma/alpaca-cleaned"
output_model_name: "your-username/llama3-with-notifications"
output_dir: "./outputs/notified-training/"

# Training Configuration
training_type: "lora"
max_seq_length: 2048

# Loss Masking Strategy (default: full)
loss_masking_strategy: "full"

# Hyperparameters
batch_size: 2
gradient_accumulation: 8  # Effective batch size: 16
epochs: 3
learning_rate: 3e-4
lr_scheduler_type: "cosine"
optim: "adamw_torch_fused"
save_steps: 50  # Notifications sent every 50 steps!

# ‚≠ê ntfy.sh Notifications
# Set your ntfy topic to receive push notifications
# Get notifications on your phone via the ntfy.sh app!
ntfy_topic: "your-unique-topic-name"  # Change this to your topic

# LoRA Configuration
lora:
  r: 128
  lora_alpha: 256
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"

# Memory Optimization
gradient_checkpointing: true
torch_compile: true
tf32: true
cache_dir: "~/.cache/late/models"

# Logging and Upload
report_to_wandb: true
upload_to_hub: true

# HuggingFace Token
hf_token: "${HF_TOKEN}"  # Or set explicitly

# How to use ntfy.sh notifications:
# 1. Install ntfy app on your phone (iOS/Android)
# 2. Subscribe to your topic (e.g., "mytrain-20250118")
# 3. Set ntfy_topic above to your topic name
# 4. Receive notifications on:
#    - Training start
#    - Checkpoint saves (every save_steps)
#    - Training completion
#    - Upload success/failure
#    - Checkpoint resume events
